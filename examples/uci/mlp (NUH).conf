name: "deep-big-simple-mlp"
train_steps: 10000
test_steps:0
test_frequency:0
display_frequency:30
debug: true
updater{
  base_learning_rate: 0.1
  learning_rate_change_method: kFixed
  param_type: "Param"
}

neuralnet {
layer {
  name: "data"
  type: "kShardData"
  data_param {
    path: "examples/NUH/NUH_Readmission_train_shard"
    batchsize: 128
  }
  exclude: kTest
}

layer{
  name:"Readmission"
  type: "kReadmissionData"
  srclayers: "data"
}

layer{
  name: "label"
  type: "kLabel"
  srclayers: "data"
}

layer{
  name: "fc1"
  type: "kInnerProduct"
  srclayers:"Readmission"
  inner_product_param{
    num_output: 50
  }
  param{
    name: "weight"
    init_method: kUniformSqrtFanInOut
    low:-2.45
    high:2.45
  }
  param{
    name: "bias"
    init_method: kConstant
    value: 0.0
  }
}

layer{
  name: "tanh1"
  type:"kTanh"
  srclayers:"fc1"
}

layer{
  name: "fc2"
  type: "kInnerProduct"
  srclayers:"tanh1"
  inner_product_param{
    num_output: 2
  }
  param{
    name: "weight"
    init_method: kUniformSqrtFanInOut
    low:-2.45
    high:2.45
  }
  param{
    name: "bias"
    init_method: kConstant
    value: 0.0
  }
}

layer{
  name: "loss"
  type:"kSoftmaxLoss"
  softmaxloss_param{
    topk:1
  }
  srclayers:"fc2"
  srclayers:"label"
}
}
